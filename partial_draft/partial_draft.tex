% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Zero-shot Question Generation with GPT-J}

% Author information can be set in various styles:

% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\

% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Sukhrit Rao \\
  New York University \\
  \texttt{str8775@nyu.edu} \\\And
  Rohit Bollineni \\
  New York University \\
  \texttt{rb4987@nyu.edu} \\\And
  Hasan Khan \\
  New York University \\
  \texttt{hk3550@nyu.edu} \\}

\begin{document}
\maketitle
\begin{abstract}
The last thing you figure out in writing a [paper] is what to put first - Pascal
\end{abstract}

\section{Introduction}

Asking good questions forms an essential part of assessing a student’s grasp of certain concepts. Instructors spend considerable time constructing exam and assignment questions that assess students on material taught in the classroom. Neural Question Generation (QG) systems aim to automate the process of question construction by generating novel questions given a particular context. QG systems with configurable difficulty settings could help offer students custom material based on their individual ability, and act as a foundation for adaptive learning \citep{adaptive-education:8}. 

Recent work in QG has focused on generating quiz-style questions \citep{Quiz:1}, with particular focus on generating questions of selected difficulty levels \citep{Difficulty:3}. However, these techniques have relied on fine-tuning a language model on a task-specific dataset such as SQuAD or RACE \citep{RACE:2}. These models are limited in their domain of use and do not generalize out-of-distribution (citation???). Moreover, constructing such datasets is time-consuming and costly, and thus not a viable means for widespread adoption. In this paper, we propose using GPT-J in a zero-shot setting to produce questions that are \textit{fluent} in linguistic construction, \textit{relevant} to the input context, and appropriately \textit{difficult} as requested in the input. We compare our work against a baseline GPT-J model fine-tuned on the task.

In the context of reading comprehension, we look at two types of QG variants. In answer-focused QG, a reference passage and an answer are passed as inputs into the system, resulting in the generation of questions relevant to the input answer. In general QG, only a context passage is passed as input, resulting in the generation of unmapped questions relevant to the context.

\section{Method}

\subsection{Data}

We use RACE, a compilation of reading comprehension questions from middle and high school English exams administered to Chinese students, to fine tune and prompt our GPT-J model. Questions that are generic (i.e less than 5 words, non-specific to the context, etc.) are dropped, alongside with any questions with numeric answers, in order to prevent the model from generating vague questions (???). 

For the answer-focused setting, training inputs to the QG model are composed of a question, an answer, a context and a difficulty. We determine difficulty by mapping middle school questions to \textit{easy} and high school questions to \textit{hard} difficulties.   ---- data points are used for fine-tuning, and 1695 for testing. The same 1695 datapoints are used for prompting in the zero shot setting. We only use contexts that have at least two associated questions, in order to allow for zero shot prompting for every test context.  

A similar input is used for the general setting, except no answer is included.  ---- data points are used for general fine-tuning, and ---- for general prompting in the zero shot setting. We experiment with various prompts for the zero shot setting (insert future prompt variant info here). An example of the zero shot input prompt is shown below: 

\begin{quote}
\textbf{Context}: Although most weddings follow long-held traditions, there's still room for American individualism. For example, the usual place for a wedding is in a church. But some people get married outdoors in a scenic spot. A few even have the ceremony while skydiving or riding on horseback! The couple may invite hundreds of people or just a few close friends. They choose their own style of colors, decorations and music during the ceremony. But some things rarely change. The bride usually wears a beautiful long white wedding dress. She traditionally wears "something old, something new, something borrowed and something blue." The groom wears a formal suit.

\textbf{Difficulty}: Hard. 

\textbf{Answer}: Some people choose their own style of weddings. 

\textbf{Question}: <generated question>

\end{quote}

In this instance, the true question is "Which of the following best shows American individualism?"

\subsection{Model}

For generating questions, we choose GPT-J-6B \citep{gpt-j:4} for its manageable parameter size (6 billion) and open-source code, allowing us to fine-tune the model. We use the following model parameter values: 

\begin{table}[h]
\centering
\begin{tabular}{lc}
\hline
\textbf{Parameter} & \textbf{Value}\\
\hline
do-sample & True \\
temperature & 1.0 \\
max-new-tokens & 250 \\
top-k & 50 \\ 
top-p & 1.0  \\ 
length-penalty & 0.8 \\
return-dict-in-generate & False \\
\hline
\end{tabular}
\end{table}


\subsection{Evaluation}

Generated questions are evaluated on three criteria: fluency, relevancy, and difficulty. Generally, we use a mix of manual human-centric evaluation, the gold standard in evaluating outputs from NLG systems \citep{human-eval:7}, and limited use of automated model based evaluations.

\textbf{Fluency} determines weather a question is easy to read and understand, without taking the source (passage or reference question) into account, and is manually evaluated on a 0-3 Likert scale (ranging from poor to excellent). \textbf{Relevancy} \cite{relevancy:5} determines whether the generated questions and input questions are topically related, and measured using manual evaluation on a 0-3 Likert scale (ranging from relevant to irrelevant) as well as with evaluation metrics including BLEU (which we use to measures N-gram overlap between reference text and generated text), BLEURT (which uses a transformer model trained to score the similarity between a reference and hypothesis text) and ROUGE-L (which measures the recall and precision of longest common subsequence between a reference and hypothesis
text). \textbf{Difficulty} is determined by checking if the generated question’s difficulty matches that of the input difficulty fed to the model, and is measured in an automated way using a GPT-J classifier trained on RACE to classify questions as easy or hard. We compare the classifier's output difficulty with the requested difficulty from the input, and evaluate the F1 score.  

\section{Results}

The first line of the file must be
\begin{quote}
\begin{verbatim}
\documentclass[11pt]{article}
\end{verbatim}
\end{quote}

To load the style file in the review version:
\begin{quote}
\begin{verbatim}
\usepackage[review]{acl}
\end{verbatim}
\end{quote}
For the final version, omit the \verb|review| option:
\begin{quote}
\begin{verbatim}
\usepackage{acl}
\end{verbatim}
\end{quote}

To use Times Roman, put the following in the preamble:
\begin{quote}
\begin{verbatim}
\usepackage{times}
\end{verbatim}
\end{quote}
(Alternatives like txfonts or newtx are also acceptable.)

Please see the \LaTeX{} source of this document for comments on other packages that may be useful.

Set the title and author using \verb|\title| and \verb|\author|. Within the author list, format multiple authors using \verb|\and| and \verb|\And| and \verb|\AND|; please see the \LaTeX{} source for examples.

By default, the box containing the title and author names is set to the minimum of 5 cm. If you need more space, include the following in the preamble:
\begin{quote}
\begin{verbatim}
\setlength\titlebox{<dim>}
\end{verbatim}
\end{quote}
where \verb|<dim>| is replaced with a length. Do not set this length smaller than 5 cm.

\section{Document Body}

\subsection{Footnotes}

Footnotes are inserted with the \verb|\footnote| command.\footnote{This is a footnote.}

\subsection{Tables and figures}

See Table~\ref{tab:accents} for an example of a table and its caption.
\textbf{Do not override the default caption sizes.}

\begin{table}
\centering
\begin{tabular}{lc}
\hline
\textbf{Command} & \textbf{Output}\\
\hline
\verb|{\"a}| & {\"a} \\
\verb|{\^e}| & {\^e} \\
\verb|{\`i}| & {\`i} \\ 
\verb|{\.I}| & {\.I} \\ 
\verb|{\o}| & {\o} \\
\verb|{\'u}| & {\'u}  \\ 
\verb|{\aa}| & {\aa}  \\\hline
\end{tabular}
\begin{tabular}{lc}
\hline
\end{tabular}
\caption{Example commands for accented characters, to be used in, \emph{e.g.}, Bib\TeX{} entries.}
\label{tab:accents}
\end{table}

\subsection{Hyperlinks}

Users of older versions of \LaTeX{} may encounter the following error during compilation: 
\begin{quote}
\tt\verb|\pdfendlink| ended up in different nesting level than \verb|\pdfstartlink|.
\end{quote}
This happens when pdf\LaTeX{} is used and a citation splits across a page boundary. The best way to fix this is to upgrade \LaTeX{} to 2018-12-01 or later.

\subsection{Citations}

\begin{table*}
\centering
\begin{tabular}{lll}
\hline
\textbf{Output} & \textbf{natbib command} & \textbf{Old ACL-style command}\\
\hline
\citep{Gusfield:97} & \verb|\citep| & \verb|\cite| \\
\citealp{Gusfield:97} & \verb|\citealp| & no equivalent \\
\citet{Gusfield:97} & \verb|\citet| & \verb|\newcite| \\
\citeyearpar{Gusfield:97} & \verb|\citeyearpar| & \verb|\shortcite| \\
\hline
\end{tabular}
\caption{\label{citation-guide}
Citation commands supported by the style file.
The style is based on the natbib package and supports all natbib citation commands.
It also supports commands defined in previous ACL style files for compatibility.
}
\end{table*}

Table~\ref{citation-guide} shows the syntax supported by the style files.
We encourage you to use the natbib styles.
You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

\subsection{References}

\nocite{Ando2005,borschinger-johnson-2011-particle,andrew2007scalable,rasooli-tetrault-2015,goodman-etal-2016-noise,harper-2014-learning}

The \LaTeX{} and Bib\TeX{} style files provided roughly follow the American Psychological Association format.
If your own bib file is named \texttt{custom.bib}, then placing the following before any appendices in your \LaTeX{} file will generate the references section for you:
\begin{quote}
\begin{verbatim}
\bibliographystyle{acl_natbib}
\bibliography{custom}
\end{verbatim}
\end{quote}

You can obtain the complete ACL Anthology as a Bib\TeX{} file from \url{https://aclweb.org/anthology/anthology.bib.gz}.
To include both the Anthology and your own .bib file, use the following instead of the above.
\begin{quote}
\begin{verbatim}
\bibliographystyle{acl_natbib}
\bibliography{anthology,custom}
\end{verbatim}
\end{quote}

Please see Section~\ref{sec:bibtex} for information on preparing Bib\TeX{} files.

\subsection{Appendices}

Use \verb|\appendix| before any appendix section to switch the section numbering over to letters. See Appendix~\ref{sec:appendix} for an example.

\section{Bib\TeX{} Files}
\label{sec:bibtex}

Unicode cannot be used in Bib\TeX{} entries, and some ways of typing special characters can disrupt Bib\TeX's alphabetization. The recommended way of typing special characters is shown in Table~\ref{tab:accents}.

Please ensure that Bib\TeX{} records contain DOIs or URLs when possible, and for all the ACL materials that you reference.
Use the \verb|doi| field for DOIs and the \verb|url| field for URLs.
If a Bib\TeX{} entry has a URL or DOI field, the paper title in the references section will appear as a hyperlink to the paper, using the hyperref \LaTeX{} package.

\section*{Acknowledgements}

This document has been adapted
by Steven Bethard, Ryan Cotterell and Rui Yan
from the instructions for earlier ACL and NAACL proceedings, including those for 
ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
NAACL 2019 by Stephanie Lukin and Alla Roskovskaya, 
ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu, 
NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
ACL 2017 by Dan Gildea and Min-Yen Kan, 
NAACL 2017 by Margaret Mitchell, 
ACL 2012 by Maggie Li and Michael White, 
ACL 2010 by Jing-Shin Chang and Philipp Koehn, 
ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui, 
ACL 2005 by Hwee Tou Ng and Kemal Oflazer, 
ACL 2002 by Eugene Charniak and Dekang Lin, 
and earlier ACL and EACL formats written by several people, including
John Chen, Henry S. Thompson and Donald Walker.
Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Entries for the entire Anthology, followed by custom entries
\bibliography{citations}
\bibliographystyle{acl_natbib}

\appendix

\section{Example Appendix}
\label{sec:appendix}

This is an appendix.

\end{document}